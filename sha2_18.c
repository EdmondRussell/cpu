#include "miner.h"

#include <string.h>
#include <inttypes.h>

#if defined(USE_ASM) && defined(__arm__) && defined(__APCS_32__)
#define EXTERN_SHA256
#endif

static const uint32_t sha256_h[8] = {
	0x6a09e667, 0xbb67ae85, 0x3c6ef372, 0xa54ff53a,
	0x510e527f, 0x9b05688c, 0x1f83d9ab, 0x5be0cd19
};

static const uint32_t sha256_k[64] = {
	0x428a2f98, 0x71374491, 0xb5c0fbcf, 0xe9b5dba5,
	0x3956c25b, 0x59f111f1, 0x923f82a4, 0xab1c5ed5,
	0xd807aa98, 0x12835b01, 0x243185be, 0x550c7dc3,
	0x72be5d74, 0x80deb1fe, 0x9bdc06a7, 0xc19bf174,
	0xe49b69c1, 0xefbe4786, 0x0fc19dc6, 0x240ca1cc,
	0x2de92c6f, 0x4a7484aa, 0x5cb0a9dc, 0x76f988da,
	0x983e5152, 0xa831c66d, 0xb00327c8, 0xbf597fc7,
	0xc6e00bf3, 0xd5a79147, 0x06ca6351, 0x14292967,
	0x27b70a85, 0x2e1b2138, 0x4d2c6dfc, 0x53380d13,
	0x650a7354, 0x766a0abb, 0x81c2c92e, 0x92722c85,
	0xa2bfe8a1, 0xa81a664b, 0xc24b8b70, 0xc76c51a3,
	0xd192e819, 0xd6990624, 0xf40e3585, 0x106aa070,
	0x19a4c116, 0x1e376c08, 0x2748774c, 0x34b0bcb5,
	0x391c0cb3, 0x4ed8aa4a, 0x5b9cca4f, 0x682e6ff3,
	0x748f82ee, 0x78a5636f, 0x84c87814, 0x8cc70208,
	0x90befffa, 0xa4506ceb, 0xbef9a3f7, 0xc67178f2
};

void sha256_init(uint32_t *state)
{
	memcpy(state, sha256_h, 32);
}

/* Elementary functions used by SHA256 */
#define Ch(x, y, z)     ((x & (y ^ z)) ^ z)
#define Maj(x, y, z)    ((x & (y | z)) | (y & z))
#define ROTR(x, n)      ((x >> n) | (x << (32 - n)))
#define S0(x)           (ROTR(x, 2) ^ ROTR(x, 13) ^ ROTR(x, 22))
#define S1(x)           (ROTR(x, 6) ^ ROTR(x, 11) ^ ROTR(x, 25))
#define s0(x)           (ROTR(x, 7) ^ ROTR(x, 18) ^ (x >> 3))
#define s1(x)           (ROTR(x, 17) ^ ROTR(x, 19) ^ (x >> 10))

/* SHA256 round function */
#define RND(a, b, c, d, e, f, g, h, k) \
	do { \
		t0 = h + S1(e) + Ch(e, f, g) + k; \
		t1 = S0(a) + Maj(a, b, c); \
		d += t0; \
		h  = t0 + t1; \
	} while (0)

/* Adjusted round function for rotating state */
#define RNDr(S, W, i) \
	RND(S[(64 - i) % 8], S[(65 - i) % 8], \
	    S[(66 - i) % 8], S[(67 - i) % 8], \
	    S[(68 - i) % 8], S[(69 - i) % 8], \
	    S[(70 - i) % 8], S[(71 - i) % 8], \
	    W[i] + sha256_k[i])

#ifndef EXTERN_SHA256

/*
 * SHA256 block compression function.  The 256-bit state is transformed via
 * the 512-bit input block to produce a new state.
 */
void sha256_transform(uint32_t *state, const uint32_t *block, int swap)
{
	uint32_t W[64];
	uint32_t S[8];
	uint32_t t0, t1;
	int i;

	/* 1. Prepare message schedule W. */
	if (swap) {
		for (i = 0; i < 16; i++)
			W[i] = swab32(block[i]);
	} else
		memcpy(W, block, 64);
	for (i = 16; i < 64; i += 2) {
		W[i]   = s1(W[i - 2]) + W[i - 7] + s0(W[i - 15]) + W[i - 16];
		W[i+1] = s1(W[i - 1]) + W[i - 6] + s0(W[i - 14]) + W[i - 15];
	}

	/* 2. Initialize working variables. */
	memcpy(S, state, 32);

	/* 3. Mix. */
	RNDr(S, W,  0);
	RNDr(S, W,  1);
	RNDr(S, W,  2);
	RNDr(S, W,  3);
	RNDr(S, W,  4);
	RNDr(S, W,  5);
	RNDr(S, W,  6);
	RNDr(S, W,  7);
	RNDr(S, W,  8);
	RNDr(S, W,  9);
	RNDr(S, W, 10);
	RNDr(S, W, 11);
	RNDr(S, W, 12);
	RNDr(S, W, 13);
	RNDr(S, W, 14);
	RNDr(S, W, 15);
	RNDr(S, W, 16);
	RNDr(S, W, 17);
	RNDr(S, W, 18);
	RNDr(S, W, 19);
	RNDr(S, W, 20);
	RNDr(S, W, 21);
	RNDr(S, W, 22);
	RNDr(S, W, 23);
	RNDr(S, W, 24);
	RNDr(S, W, 25);
	RNDr(S, W, 26);
	RNDr(S, W, 27);
	RNDr(S, W, 28);
	RNDr(S, W, 29);
	RNDr(S, W, 30);
	RNDr(S, W, 31);
	RNDr(S, W, 32);
	RNDr(S, W, 33);
	RNDr(S, W, 34);
	RNDr(S, W, 35);
	RNDr(S, W, 36);
	RNDr(S, W, 37);
	RNDr(S, W, 38);
	RNDr(S, W, 39);
	RNDr(S, W, 40);
	RNDr(S, W, 41);
	RNDr(S, W, 42);
	RNDr(S, W, 43);
	RNDr(S, W, 44);
	RNDr(S, W, 45);
	RNDr(S, W, 46);
	RNDr(S, W, 47);
	RNDr(S, W, 48);
	RNDr(S, W, 49);
	RNDr(S, W, 50);
	RNDr(S, W, 51);
	RNDr(S, W, 52);
	RNDr(S, W, 53);
	RNDr(S, W, 54);
	RNDr(S, W, 55);
	RNDr(S, W, 56);
	RNDr(S, W, 57);
	RNDr(S, W, 58);
	RNDr(S, W, 59);
	RNDr(S, W, 60);
	RNDr(S, W, 61);
	RNDr(S, W, 62);
	RNDr(S, W, 63);

	/* 4. Mix local working variables into global state */
	for (i = 0; i < 8; i++)
		state[i] += S[i];
}

#endif /* EXTERN_SHA256 */


static const uint32_t sha256d_hash1[16] = {
	0x00000000, 0x00000000, 0x00000000, 0x00000000,
	0x00000000, 0x00000000, 0x00000000, 0x00000000,
	0x80000000, 0x00000000, 0x00000000, 0x00000000,
	0x00000000, 0x00000000, 0x00000000, 0x00000100
};

static void sha256d_80_swap(uint32_t *hash, const uint32_t *data)
{
	uint32_t S[16];
	int i;

	sha256_init(S);
	sha256_transform(S, data, 0);
	sha256_transform(S, data + 16, 0);
	memcpy(S + 8, sha256d_hash1 + 8, 32);
	sha256_init(hash);
	sha256_transform(hash, S, 0);
	for (i = 0; i < 8; i++)
		hash[i] = swab32(hash[i]);
}

extern void sha256d(unsigned char *hash, const unsigned char *data, int len)
{
	uint32_t S[16], T[16];
	int i, r;

	sha256_init(S);
	for (r = len; r > -9; r -= 64) {
		if (r < 64)
			memset(T, 0, 64);
		memcpy(T, data + len - r, r > 64 ? 64 : (r < 0 ? 0 : r));
		if (r >= 0 && r < 64)
			((unsigned char *)T)[r] = 0x80;
		for (i = 0; i < 16; i++)
			T[i] = be32dec(T + i);
		if (r < 56)
			T[15] = 8 * len;
		sha256_transform(S, T, 0);
	}
	memcpy(S + 8, sha256d_hash1 + 8, 32);
	sha256_init(T);
	sha256_transform(T, S, 0);
	for (i = 0; i < 8; i++)
		be32enc((uint32_t *)hash + i, T[i]);
}

static inline void sha256d_preextend(uint32_t *W)
{
	W[16] = s1(W[14]) + W[ 9] + s0(W[ 1]) + W[ 0];
	W[17] = s1(W[15]) + W[10] + s0(W[ 2]) + W[ 1];
	W[18] = s1(W[16]) + W[11]             + W[ 2];
	W[19] = s1(W[17]) + W[12] + s0(W[ 4]);
	W[20] =             W[13] + s0(W[ 5]) + W[ 4];
	W[21] =             W[14] + s0(W[ 6]) + W[ 5];
	W[22] =             W[15] + s0(W[ 7]) + W[ 6];
	W[23] =             W[16] + s0(W[ 8]) + W[ 7];
	W[24] =             W[17] + s0(W[ 9]) + W[ 8];
	W[25] =                     s0(W[10]) + W[ 9];
	W[26] =                     s0(W[11]) + W[10];
	W[27] =                     s0(W[12]) + W[11];
	W[28] =                     s0(W[13]) + W[12];
	W[29] =                     s0(W[14]) + W[13];
	W[30] =                     s0(W[15]) + W[14];
	W[31] =                     s0(W[16]) + W[15];
}

static inline void sha256d_prehash(uint32_t *S, const uint32_t *W)
{
	uint32_t t0, t1;
	RNDr(S, W, 0);
	RNDr(S, W, 1);
	RNDr(S, W, 2);
}

#ifdef EXTERN_SHA256

void sha256d_ms(uint32_t *hash, uint32_t *W,
	const uint32_t *midstate, const uint32_t *prehash);

#else

static inline void sha256d_ms(uint32_t *hash, uint32_t *W,
	const uint32_t *midstate, const uint32_t *prehash)
{
	uint32_t S[64];
	uint32_t t0, t1;
	int i;

	S[18] = W[18];
	S[19] = W[19];
	S[20] = W[20];
	S[22] = W[22];
	S[23] = W[23];
	S[24] = W[24];
	S[30] = W[30];
	S[31] = W[31];

	W[18] += s0(W[3]);
	W[19] += W[3];
	W[20] += s1(W[18]);
	W[21]  = s1(W[19]);
	W[22] += s1(W[20]);
	W[23] += s1(W[21]);
	W[24] += s1(W[22]);
	W[25]  = s1(W[23]) + W[18];
	W[26]  = s1(W[24]) + W[19];
	W[27]  = s1(W[25]) + W[20];
	W[28]  = s1(W[26]) + W[21];
	W[29]  = s1(W[27]) + W[22];
	W[30] += s1(W[28]) + W[23];
	W[31] += s1(W[29]) + W[24];
	for (i = 32; i < 64; i += 2) {
		W[i]   = s1(W[i - 2]) + W[i - 7] + s0(W[i - 15]) + W[i - 16];
		W[i+1] = s1(W[i - 1]) + W[i - 6] + s0(W[i - 14]) + W[i - 15];
	}

	memcpy(S, prehash, 32);

	RNDr(S, W,  3);
	RNDr(S, W,  4);
	RNDr(S, W,  5);
	RNDr(S, W,  6);
	RNDr(S, W,  7);
	RNDr(S, W,  8);
	RNDr(S, W,  9);
	RNDr(S, W, 10);
	RNDr(S, W, 11);
	RNDr(S, W, 12);
	RNDr(S, W, 13);
	RNDr(S, W, 14);
	RNDr(S, W, 15);
	RNDr(S, W, 16);
	RNDr(S, W, 17);
	RNDr(S, W, 18);
	RNDr(S, W, 19);
	RNDr(S, W, 20);
	RNDr(S, W, 21);
	RNDr(S, W, 22);
	RNDr(S, W, 23);
	RNDr(S, W, 24);
	RNDr(S, W, 25);
	RNDr(S, W, 26);
	RNDr(S, W, 27);
	RNDr(S, W, 28);
	RNDr(S, W, 29);
	RNDr(S, W, 30);
	RNDr(S, W, 31);
	RNDr(S, W, 32);
	RNDr(S, W, 33);
	RNDr(S, W, 34);
	RNDr(S, W, 35);
	RNDr(S, W, 36);
	RNDr(S, W, 37);
	RNDr(S, W, 38);
	RNDr(S, W, 39);
	RNDr(S, W, 40);
	RNDr(S, W, 41);
	RNDr(S, W, 42);
	RNDr(S, W, 43);
	RNDr(S, W, 44);
	RNDr(S, W, 45);
	RNDr(S, W, 46);
	RNDr(S, W, 47);
	RNDr(S, W, 48);
	RNDr(S, W, 49);
	RNDr(S, W, 50);
	RNDr(S, W, 51);
	RNDr(S, W, 52);
	RNDr(S, W, 53);
	RNDr(S, W, 54);
	RNDr(S, W, 55);
	RNDr(S, W, 56);
	RNDr(S, W, 57);
	RNDr(S, W, 58);
	RNDr(S, W, 59);
	RNDr(S, W, 60);
	RNDr(S, W, 61);
	RNDr(S, W, 62);
	RNDr(S, W, 63);

	for (i = 0; i < 8; i++)
		S[i] += midstate[i];
	
	W[18] = S[18];
	W[19] = S[19];
	W[20] = S[20];
	W[22] = S[22];
	W[23] = S[23];
	W[24] = S[24];
	W[30] = S[30];
	W[31] = S[31];
	
	memcpy(S + 8, sha256d_hash1 + 8, 32);
	S[16] = s1(sha256d_hash1[14]) + sha256d_hash1[ 9] + s0(S[ 1]) + S[ 0];
	S[17] = s1(sha256d_hash1[15]) + sha256d_hash1[10] + s0(S[ 2]) + S[ 1];
	S[18] = s1(S[16]) + sha256d_hash1[11] + s0(S[ 3]) + S[ 2];
	S[19] = s1(S[17]) + sha256d_hash1[12] + s0(S[ 4]) + S[ 3];
	S[20] = s1(S[18]) + sha256d_hash1[13] + s0(S[ 5]) + S[ 4];
	S[21] = s1(S[19]) + sha256d_hash1[14] + s0(S[ 6]) + S[ 5];
	S[22] = s1(S[20]) + sha256d_hash1[15] + s0(S[ 7]) + S[ 6];
	S[23] = s1(S[21]) + S[16] + s0(sha256d_hash1[ 8]) + S[ 7];
	S[24] = s1(S[22]) + S[17] + s0(sha256d_hash1[ 9]) + sha256d_hash1[ 8];
	S[25] = s1(S[23]) + S[18] + s0(sha256d_hash1[10]) + sha256d_hash1[ 9];
	S[26] = s1(S[24]) + S[19] + s0(sha256d_hash1[11]) + sha256d_hash1[10];
	S[27] = s1(S[25]) + S[20] + s0(sha256d_hash1[12]) + sha256d_hash1[11];
	S[28] = s1(S[26]) + S[21] + s0(sha256d_hash1[13]) + sha256d_hash1[12];
	S[29] = s1(S[27]) + S[22] + s0(sha256d_hash1[14]) + sha256d_hash1[13];
	S[30] = s1(S[28]) + S[23] + s0(sha256d_hash1[15]) + sha256d_hash1[14];
	S[31] = s1(S[29]) + S[24] + s0(S[16])             + sha256d_hash1[15];
	for (i = 32; i < 60; i += 2) {
		S[i]   = s1(S[i - 2]) + S[i - 7] + s0(S[i - 15]) + S[i - 16];
		S[i+1] = s1(S[i - 1]) + S[i - 6] + s0(S[i - 14]) + S[i - 15];
	}
	S[60] = s1(S[58]) + S[53] + s0(S[45]) + S[44];

	sha256_init(hash);

	RNDr(hash, S,  0);
	RNDr(hash, S,  1);
	RNDr(hash, S,  2);
	RNDr(hash, S,  3);
	RNDr(hash, S,  4);
	RNDr(hash, S,  5);
	RNDr(hash, S,  6);
	RNDr(hash, S,  7);
	RNDr(hash, S,  8);
	RNDr(hash, S,  9);
	RNDr(hash, S, 10);
	RNDr(hash, S, 11);
	RNDr(hash, S, 12);
	RNDr(hash, S, 13);
	RNDr(hash, S, 14);
	RNDr(hash, S, 15);
	RNDr(hash, S, 16);
	RNDr(hash, S, 17);
	RNDr(hash, S, 18);
	RNDr(hash, S, 19);
	RNDr(hash, S, 20);
	RNDr(hash, S, 21);
	RNDr(hash, S, 22);
	RNDr(hash, S, 23);
	RNDr(hash, S, 24);
	RNDr(hash, S, 25);
	RNDr(hash, S, 26);
	RNDr(hash, S, 27);
	RNDr(hash, S, 28);
	RNDr(hash, S, 29);
	RNDr(hash, S, 30);
	RNDr(hash, S, 31);
	RNDr(hash, S, 32);
	RNDr(hash, S, 33);
	RNDr(hash, S, 34);
	RNDr(hash, S, 35);
	RNDr(hash, S, 36);
	RNDr(hash, S, 37);
	RNDr(hash, S, 38);
	RNDr(hash, S, 39);
	RNDr(hash, S, 40);
	RNDr(hash, S, 41);
	RNDr(hash, S, 42);
	RNDr(hash, S, 43);
	RNDr(hash, S, 44);
	RNDr(hash, S, 45);
	RNDr(hash, S, 46);
	RNDr(hash, S, 47);
	RNDr(hash, S, 48);
	RNDr(hash, S, 49);
	RNDr(hash, S, 50);
	RNDr(hash, S, 51);
	RNDr(hash, S, 52);
	RNDr(hash, S, 53);
	RNDr(hash, S, 54);
	RNDr(hash, S, 55);
	RNDr(hash, S, 56);
	
	hash[2] += hash[6] + S1(hash[3]) + Ch(hash[3], hash[4], hash[5])
	         + S[57] + sha256_k[57];
	hash[1] += hash[5] + S1(hash[2]) + Ch(hash[2], hash[3], hash[4])
	         + S[58] + sha256_k[58];
	hash[0] += hash[4] + S1(hash[1]) + Ch(hash[1], hash[2], hash[3])
	         + S[59] + sha256_k[59];
	hash[7] += hash[3] + S1(hash[0]) + Ch(hash[0], hash[1], hash[2])
	         + S[60] + sha256_k[60]
	         + sha256_h[7];
}

#endif /* EXTERN_SHA256 */

#ifdef HAVE_SHA256_4WAY

void sha256d_ms_4way(uint32_t *hash,  uint32_t *data,
	const uint32_t *midstate, const uint32_t *prehash);

static inline int scanhash_sha256d_4way(int thr_id, struct work *work,
	uint32_t max_nonce, uint64_t *hashes_done)
{
	uint32_t _ALIGN(128) data[4 * 64];
	uint32_t _ALIGN(32) hash[4 * 8];
	uint32_t _ALIGN(32) midstate[4 * 8];
	uint32_t _ALIGN(32) prehash[4 * 8];
	uint32_t *pdata = work->data;
	uint32_t *ptarget = work->target;
	uint32_t n = pdata[19] - 1;
	const uint32_t first_nonce = pdata[19];
	const uint32_t Htarg = ptarget[7];
	int i, j;
	
	memcpy(data, pdata + 16, 64);
	sha256d_preextend(data);
	for (i = 31; i >= 0; i--)
		for (j = 0; j < 4; j++)
			data[i * 4 + j] = data[i];
	
	sha256_init(midstate);
	sha256_transform(midstate, pdata, 0);
	memcpy(prehash, midstate, 32);
	sha256d_prehash(prehash, pdata + 16);
	for (i = 7; i >= 0; i--) {
		for (j = 0; j < 4; j++) {
			midstate[i * 4 + j] = midstate[i];
			prehash[i * 4 + j] = prehash[i];
		}
	}
	
	do {
		for (i = 0; i < 4; i++)
			data[4 * 3 + i] = ++n;
		
		sha256d_ms_4way(hash, data, midstate, prehash);
		
		for (i = 0; i < 4; i++) {
			if (swab32(hash[4 * 7 + i]) <= Htarg) {
				pdata[19] = data[4 * 3 + i];
				sha256d_80_swap(hash, pdata);
				if (fulltest(hash, ptarget)) {
					work_set_target_ratio(work, hash);
					*hashes_done = n - first_nonce + 1;
					return 1;
				}
			}
		}
	} while (n < max_nonce && !work_restart[thr_id].restart);
	
	*hashes_done = n - first_nonce + 1;
	pdata[19] = n;
	return 0;
}

#endif /* HAVE_SHA256_4WAY */

#ifdef HAVE_SHA256_8WAY

void sha256d_ms_8way(uint32_t *hash,  uint32_t *data,
	const uint32_t *midstate, const uint32_t *prehash);

static inline int scanhash_sha256d_8way(int thr_id, struct work *work,
	uint32_t max_nonce, uint64_t *hashes_done)
{
	uint32_t _ALIGN(128) data[8 * 64];
	uint32_t _ALIGN(32)  hash[8 * 8];
	uint32_t _ALIGN(32)  midstate[8 * 8];
	uint32_t _ALIGN(32)  prehash[8 * 8];
	uint32_t *pdata = work->data;
	uint32_t *ptarget = work->target;
	uint32_t n = pdata[19] - 1;
	const uint32_t first_nonce = pdata[19];
	const uint32_t Htarg = ptarget[7];
	int i, j;
	
	memcpy(data, pdata + 16, 64);
	sha256d_preextend(data);
	for (i = 31; i >= 0; i--)
		for (j = 0; j < 8; j++)
			data[i * 8 + j] = data[i];
	
	sha256_init(midstate);
	sha256_transform(midstate, pdata, 0);
	memcpy(prehash, midstate, 32);
	sha256d_prehash(prehash, pdata + 16);
	for (i = 7; i >= 0; i--) {
		for (j = 0; j < 8; j++) {
			midstate[i * 8 + j] = midstate[i];
			prehash[i * 8 + j] = prehash[i];
		}
	}
	
	do {
		for (i = 0; i < 8; i++)
			data[8 * 3 + i] = ++n;
		
		sha256d_ms_8way(hash, data, midstate, prehash);
		
		for (i = 0; i < 8; i++) {
			if (swab32(hash[8 * 7 + i]) <= Htarg) {
				pdata[19] = data[8 * 3 + i];
				sha256d_80_swap(hash, pdata);
				if (fulltest(hash, ptarget)) {
					work_set_target_ratio(work, hash);
					*hashes_done = n - first_nonce + 1;
					return 1;
				}
			}
		}
	} while (n < max_nonce && !work_restart[thr_id].restart);
	
	*hashes_done = n - first_nonce + 1;
	pdata[19] = n;
	return 0;
}

#endif /* HAVE_SHA256_8WAY */

int scanhash_sha256d(int thr_id, struct work *work, uint32_t max_nonce, uint64_t *hashes_done)
{
	uint32_t _ALIGN(128) data[64];
	uint32_t _ALIGN(32) hash[8];
	uint32_t _ALIGN(32) midstate[8];
	uint32_t _ALIGN(32) prehash[8];
	uint32_t *pdata = work->data;
	uint32_t *ptarget = work->target;
	const uint32_t first_nonce = pdata[19];
	const uint32_t Htarg = ptarget[7];
	uint32_t n = pdata[19] - 1;
	
#ifdef HAVE_SHA256_8WAY
	if (sha256_use_8way())
		return scanhash_sha256d_8way(thr_id, work, max_nonce, hashes_done);
#endif
#ifdef HAVE_SHA256_4WAY
	if (sha256_use_4way())
		return scanhash_sha256d_4way(thr_id, work, max_nonce, hashes_done);
#endif
	
	memcpy(data, pdata + 16, 64);
	sha256d_preextend(data);
	
	sha256_init(midstate);
	sha256_transform(midstate, pdata, 0);
	memcpy(prehash, midstate, 32);
	sha256d_prehash(prehash, pdata + 16);
	
	// --- Poincaré-Perelman Topological Navigator ---
	// Treat hash space as a 3-manifold undergoing Ricci flow
	// Apply surgery theory to navigate toward simply-connected regions
	// Detect S³ topology via fundamental group approximation
	
	static double metric_tensor[3][3] = {{1,0,0},{0,1,0},{0,0,1}};  // Riemannian metric g_ij
	static double ricci_tensor[3][3] = {{0}};                       // Ricci curvature R_ij
	static double scalar_curvature = 0.0;                           // R = tr(R_ij)
	static uint64_t surgery_count = 0;                              // Topological surgeries performed
	static double flow_time = 0.0;                                  // Ricci flow parameter t
	static uint32_t fundamental_group_rels = 0;                     // Relations in π₁(M)
	static double sphere_likelihood = 0.0;                          // Probability of S³ topology
	static uint32_t last_n = 0;
	
	// Flow evolution parameter
	const double FLOW_DELTA_T = 0.001;
	const double SURGERY_THRESHOLD = 10.0;
	
	do {
		data[3] = n;
		sha256d_ms(hash, data, midstate, prehash);
		
		if (unlikely(swab32(hash[7]) <= Htarg)) {
			pdata[19] = data[3];
			sha256d_80_swap(hash, pdata);
			if (fulltest(hash, ptarget)) {
				work_set_target_ratio(work, hash);
				*hashes_done = n - first_nonce + 1;
				return 1;
			}
		}
		
		// --- Construct 3-Manifold from Hash Output ---
		// Map hash[0..7] to 3D manifold coordinates with metric
		
		double manifold_coords[3];
		manifold_coords[0] = (double)((hash[0] ^ hash[1]) % 10000) / 10000.0;
		manifold_coords[1] = (double)((hash[2] ^ hash[3]) % 10000) / 10000.0;
		manifold_coords[2] = (double)((hash[4] ^ hash[5]) % 10000) / 10000.0;
		
		// --- Compute Ricci Curvature Tensor ---
		// R_ij = ∂_k Γ^k_ij - ∂_j Γ^k_ik + Γ^k_ℓk Γ^ℓ_ij - Γ^k_ℓj Γ^ℓ_ik
		// Approximate via discrete differences in hash space
		
		for (int i = 0; i < 3; i++) {
			for (int j = 0; j < 3; j++) {
				// Christoffel symbol approximation from metric variations
				double christoffel = 0.0;
				
				// ∂g/∂x approximation via hash differentials
				uint32_t h_plus = hash[(i+1) % 8];
				uint32_t h_minus = hash[(i+7) % 8];
				double metric_deriv = ((double)(h_plus) - (double)(h_minus)) / 4294967296.0;
				
				christoffel = 0.5 * metric_deriv;
				
				// Ricci tensor component via contracted Riemann tensor
				ricci_tensor[i][j] = ricci_tensor[i][j] * 0.9 + 
				                      christoffel * christoffel * 0.1;
			}
		}
		
		// --- Scalar Curvature Calculation ---
		// R = g^ij R_ij (trace of Ricci tensor with metric)
		scalar_curvature = 0.0;
		for (int i = 0; i < 3; i++) {
			// Assuming metric inverse ≈ metric for small perturbations
			scalar_curvature += ricci_tensor[i][i] / (metric_tensor[i][i] + 1e-10);
		}
		
		// --- Ricci Flow Evolution ---
		// ∂g_ij/∂t = -2 R_ij (Hamilton's Ricci flow equation)
		
		for (int i = 0; i < 3; i++) {
			for (int j = 0; j < 3; j++) {
				double flow_update = -2.0 * ricci_tensor[i][j] * FLOW_DELTA_T;
				metric_tensor[i][j] += flow_update;
				
				// Maintain positive-definiteness
				if (i == j && metric_tensor[i][j] < 0.01) {
					metric_tensor[i][j] = 0.01;
				}
			}
		}
		
		flow_time += FLOW_DELTA_T;
		
		// --- Curvature Singularity Detection & Surgery ---
		// When curvature becomes too large, perform topological surgery
		
		double max_curvature = 0.0;
		for (int i = 0; i < 3; i++) {
			for (int j = 0; j < 3; j++) {
				if (fabs(ricci_tensor[i][j]) > max_curvature) {
					max_curvature = fabs(ricci_tensor[i][j]);
				}
			}
		}
		
		if (max_curvature > SURGERY_THRESHOLD) {
			// Perform Perelman surgery: cut out high-curvature region
			surgery_count++;
			
			// Reset metric near singularity (S² × ℝ cap insertion)
			for (int i = 0; i < 3; i++) {
				metric_tensor[i][i] = 1.0;
				for (int j = i+1; j < 3; j++) {
					metric_tensor[i][j] = 0.0;
					metric_tensor[j][i] = 0.0;
				}
			}
			
			// Reset Ricci tensor
			for (int i = 0; i < 3; i++) {
				for (int j = 0; j < 3; j++) {
					ricci_tensor[i][j] *= 0.1;
				}
			}
		}
		
		// --- Fundamental Group Approximation ---
		// π₁(M) detection via loop analysis in hash space
		// Simply-connected ⟺ π₁(M) = {e}
		
		// Detect non-trivial loops via hash periodicity
		bool loop_detected = false;
		
		// Check for hash value recurrence (crude loop detection)
		for (int offset = 1; offset < 8; offset++) {
			if (hash[0] == hash[offset]) {
				loop_detected = true;
				fundamental_group_rels++;
				break;
			}
		}
		
		// Compute loop winding via coordinate differences
		double loop_winding = 0.0;
		for (int i = 0; i < 2; i++) {
			loop_winding += fabs(manifold_coords[i] - manifold_coords[i+1]);
		}
		
		// Non-contractible loop indicator
		if (loop_winding > 0.5 && loop_winding < 0.7) {
			fundamental_group_rels++;
		}
		
		// --- S³ Topology Likelihood Estimation ---
		// Poincaré: Simply-connected closed 3-manifold is homeomorphic to S³
		
		// Indicators of S³ topology:
		// 1. Low fundamental group complexity
		double group_simplicity = 1.0 / (1.0 + sqrt((double)fundamental_group_rels));
		
		// 2. Positive scalar curvature (S³ has constant positive curvature)
		double curvature_score = (scalar_curvature > 0) ? 
		                          (1.0 / (1.0 + fabs(scalar_curvature - 6.0))) : 0.0;
		
		// 3. Successful Ricci flow convergence (few surgeries)
		double surgery_score = 1.0 / (1.0 + sqrt((double)(surgery_count + 1)));
		
		// 4. Homology sphere test: H₁(M) = 0 (approximated via loop cancellation)
		double homology_score = 1.0 - fmin(1.0, loop_winding);
		
		// Combined sphere likelihood
		sphere_likelihood = (group_simplicity * 0.3 + 
		                     curvature_score * 0.3 + 
		                     surgery_score * 0.2 + 
		                     homology_score * 0.2);
		
		// --- Thurston Geometrization ---
		// Decompose manifold into geometric pieces
		// Hash target might lie in specific geometric structure
		
		// Detect geometry type from curvature signature
		enum GeometryType {
			SPHERICAL,      // S³ (positive curvature)
			EUCLIDEAN,      // E³ (flat)
			HYPERBOLIC,     // H³ (negative curvature)
			PRODUCT,        // S² × ℝ
			TWISTED         // Other
		} geometry_type;
		
		if (scalar_curvature > 1.0) {
			geometry_type = SPHERICAL;
		} else if (scalar_curvature < -1.0) {
			geometry_type = HYPERBOLIC;
		} else if (fabs(scalar_curvature) < 0.1) {
			geometry_type = EUCLIDEAN;
		} else if (surgery_count > 0) {
			geometry_type = PRODUCT;
		} else {
			geometry_type = TWISTED;
		}
		
		// --- Nonce Perturbation via Topological Guidance ---
		
		// Component 1: Ricci flow direction
		// Flow toward regions of negative curvature
		int64_t ricci_guidance = -(int64_t)(scalar_curvature * 1024.0);
		
		// Component 2: Sphere likelihood gradient
		// Higher S³ likelihood → explore nearby
		int64_t sphere_guidance = (int64_t)((sphere_likelihood - 0.5) * 2048.0);
		
		// Component 3: Surgery-based jumps
		// Recent surgery → large topological change → big jump
		int64_t surgery_guidance = (surgery_count & 1) ? 
		                            ((hash[6] % 2048) - 1024) : 0;
		
		// Component 4: Fundamental group complexity
		// More relations → avoid region, seek simpler topology
		int64_t group_guidance = -(int64_t)(fundamental_group_rels % 512);
		
		// Component 5: Geometric structure type
		int64_t geometry_guidance = 0;
		switch (geometry_type) {
			case SPHERICAL:
				// Near S³ → fine-grained search
				geometry_guidance = (hash[7] % 128) - 64;
				break;
			case HYPERBOLIC:
				// Negative curvature → expand search
				geometry_guidance = (hash[7] % 4096) - 2048;
				break;
			case EUCLIDEAN:
				// Flat space → linear progression
				geometry_guidance = 256;
				break;
			case PRODUCT:
				// After surgery → structured jump
				geometry_guidance = (surgery_count * 512) % 2048;
				break;
			case TWISTED:
				// Complex topology → random exploration
				geometry_guidance = ((hash[6] ^ hash[7]) % 1024) - 512;
				break;
		}
		
		// Component 6: Metric determinant (volume element)
		// det(g) measures local volume, guide toward extrema
		double metric_det = metric_tensor[0][0] * metric_tensor[1][1] * metric_tensor[2][2];
		int64_t volume_guidance = (int64_t)((metric_det - 1.0) * 512.0);
		
		// Component 7: Flow time modulation
		// Long flow time → approaching limit, refine search
		int64_t time_guidance = -(int64_t)(flow_time * 10.0);
		
		// Weighted combination of topological components
		int64_t perturbation = (ricci_guidance >> 2) +
		                        (sphere_guidance >> 1) +
		                        (surgery_guidance >> 0) +
		                        (group_guidance >> 2) +
		                        (geometry_guidance >> 1) +
		                        (volume_guidance >> 3) +
		                        (time_guidance >> 4);
		
		// Perelman's κ-noncollapsing condition
		// Prevent metric from degenerating
		if (metric_det < 0.01) {
			// Force expansion away from collapsed region
			perturbation += 4096;
		}
		
		// Geometrization theorem constraint
		// In S³ regions, use finer search resolution
		if (sphere_likelihood > 0.8) {
			perturbation = perturbation >> 2;  // Reduce step size
		}
		
		// Slew rate limiting (prevent escaping manifold)
		const int32_t MAX_TOPOLOGY_JUMP = 0x2000;
		if (perturbation > MAX_TOPOLOGY_JUMP) perturbation = MAX_TOPOLOGY_JUMP;
		if (perturbation < -MAX_TOPOLOGY_JUMP) perturbation = -MAX_TOPOLOGY_JUMP;
		
		// Apply topology-guided mutation
		n = (uint32_t)((int64_t)n + perturbation);
		
		// Ensure forward progress
		if (n <= last_n)
			n = last_n + 1;
		
		last_n = n;
		
		// Periodic renormalization (prevent flow divergence)
		if ((n & 0x7FFF) == 0) {
			// Renormalize metric tensor
			double trace = metric_tensor[0][0] + metric_tensor[1][1] + metric_tensor[2][2];
			if (trace > 1e-6) {
				for (int i = 0; i < 3; i++) {
					for (int j = 0; j < 3; j++) {
						metric_tensor[i][j] *= (3.0 / trace);
					}
				}
			}
			
			// Reset flow time to prevent overflow
			flow_time = fmod(flow_time, 1000.0);
			
			// Decay topological invariants
			fundamental_group_rels = fundamental_group_rels >> 2;
			surgery_count = surgery_count >> 1;
			
			// Reset curvature accumulation
			for (int i = 0; i < 3; i++) {
				for (int j = 0; j < 3; j++) {
					ricci_tensor[i][j] *= 0.5;
				}
			}
			
			sphere_likelihood = sphere_likelihood * 0.9;
		}
		
	} while (likely(n < max_nonce && !work_restart[thr_id].restart));
	
	*hashes_done = n - first_nonce + 1;
	pdata[19] = n;
	return 0;
}
